services:
  llama-swap:
    image: ghcr.io/mostlygeek/llama-swap:cuda
    profiles: [manual]
    volumes:
      - ./.docker/llama-swap/models:/models
      - ./.docker/llama-swap/swap-config.yaml:/app/config.yaml:ro
    container_name: llama-swap
    tty: true
    ports:
      - 11544:8080
    networks:
      - synui_app
